{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os , sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bardiya/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/bardiya/projects/diffusion_air_manifolding/codes/creative-generativeai-diffusion/src/optimization_loop/../Gen_src/diffusion.py:331: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from: /home/bardiya/projects/diffusion_air_manifolding/codes/creative-generativeai-diffusion/model_weigths/model_epoch_375.pt\n"
     ]
    }
   ],
   "source": [
    "from Gen_src.diffusion import GaussianDiffusion1D\n",
    "from Gen_src.model import Unet1D\n",
    "import torch\n",
    "import os,sys\n",
    "# Add the parent directory of Gen_src to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Same architecture as in training\n",
    "model = Unet1D(\n",
    "    dim=32,\n",
    "    dim_mults=(2, 4, 8, 16),\n",
    "    channels=2,  # X and Y\n",
    "    dropout=0.1\n",
    ").cuda()  # or .to(device)\n",
    "\n",
    "# Create the same diffusion wrapper\n",
    "diffusion = GaussianDiffusion1D(\n",
    "    model,\n",
    "    seq_length=192,      # must match your training setup\n",
    "    objective='pred_noise',\n",
    "    timesteps=1000\n",
    ").cuda()  # or .to(device)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint_path = rf\"/home/bardiya/projects/diffusion_air_manifolding/codes/creative-generativeai-diffusion/model_weigths/model_epoch_375.pt\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, weights_only=True))\n",
    "model.eval()\n",
    "print(\"Loaded model weights from:\", checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(rf\"/home/bardiya/projects/diffusion_air_manifolding/codes/creative-generativeai-diffusion/data/raw\")\n",
    "coord_mm = np.load(DATA_DIR/\"coord_min_max.npy\")  # [[x_min,y_min],[x_max,y_max]]\n",
    "x_min,y_min = coord_mm[0]; x_max,y_max = coord_mm[1]\n",
    "\n",
    "def inv_coords(xs_s):                   # xs_s shape (...,2,192) tensor\n",
    "    xs_np = xs_s.permute(0,2,1).cpu().numpy()    # -> (B,192,2)\n",
    "    xs_np[...,0] = xs_np[...,0]*(x_max-x_min) + x_min\n",
    "    xs_np[...,1] = xs_np[...,1]*(y_max-y_min) + y_min\n",
    "    return xs_np                                # (B,192,2) numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:13<00:00, 76.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_to_generate = 2\n",
    "batch_size      = 2\n",
    "\n",
    "# generated_scaled = []\n",
    "# latent = torch.randn((1,2,192)).to(\"cuda\")\n",
    "# samples1 = diffusion.latent_sample(latent , is_ddim=True)\n",
    "# samples2 = diffusion.latent_sample(latent , is_ddim=True)\n",
    "# generated_samples1 = inv_coords(samples1)\n",
    "# generated_samples2 = inv_coords(samples2)\n",
    "\n",
    "\n",
    "all_latent = []\n",
    "all_shapes = []\n",
    "with torch.no_grad():\n",
    "    done = 0\n",
    "    while done < num_to_generate:\n",
    "        cur = min(batch_size, num_to_generate - done)\n",
    "        \n",
    "        latent = torch.randn((cur,2,192)).to(\"cuda\")\n",
    "        samples = diffusion.latent_sample(latent , is_ddim=True)\n",
    "        generated_real = inv_coords(samples)\n",
    "        \n",
    "        all_latent.append(latent.cpu().detach().numpy())\n",
    "        all_shapes.append(generated_real)\n",
    "        done += cur\n",
    "        print(f\"Generated {done}/{num_to_generate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_mount_path = \"/home/bardiya/projects/diffusion_air_manifolding/codes/Airfoil_MPI_system\"\n",
    "# docker_mount_path = \".\"\n",
    "\n",
    "np.save(os.path.join(docker_mount_path , \"DB2.npy\") , {\n",
    "    \"latents\": np.vstack(all_latent),\n",
    "    \"shapes\": np.vstack(all_shapes),\n",
    "    \"performances\": None\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 192, 2)\n",
      "8\n",
      "core 0:\n",
      "sample 0:\n",
      "\tUsing len 40.000 angle +0.000 \n",
      "\tResulting freestream vel x,y: 40.0,-0.0\n",
      "core 1:\n",
      "sample 1:\n",
      "\tUsing len 40.000 angle +0.000 \n",
      "\tResulting freestream vel x,y: 40.0,-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/airfoil_UANA/Airfoil_simulation_1/ShapeToPerformance.py\", line 195, in calculate_cd_cl_res\n",
      "    os.chdir(\"./Airfoil_simulation_1/OpenFOAM_%d/\" % (n))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './Airfoil_simulation_1/OpenFOAM_0/'\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/airfoil_UANA/Airfoil_simulation_1/ShapeToPerformance.py\", line 195, in calculate_cd_cl_res\n",
      "    os.chdir(\"./Airfoil_simulation_1/OpenFOAM_%d/\" % (n))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './Airfoil_simulation_1/OpenFOAM_1/'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/airfoil_UANA/performance_finding.py\", line 15, in <module>\n",
      "    performance = STP1(airfoil_shape)\n",
      "  File \"/home/airfoil_UANA/Airfoil_simulation_1/ShapeToPerformance.py\", line 267, in shape_to_performance\n",
      "    files_list = [os.path.join(Data_path, f) for f in os.listdir(Data_path) if os.path.isfile(os.path.join(Data_path, f))]\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './Airfoil_simulation_1/results/'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append(\"../OpenFoam\")\n",
    "from OpenFoam.Airfoil_simulation_1.ShapeToPerformance import shape_to_performance as STP1\n",
    "docker_container_id = \"78257c051b5b\" \n",
    "command = fr\"docker exec {docker_container_id} python3 /home/airfoil_UANA/performance_finding.py\"\n",
    "os.system(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB2 = np.load(rf\"DB2.npy\",allow_pickle=True).item()\n",
    "DB2[\"performances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
