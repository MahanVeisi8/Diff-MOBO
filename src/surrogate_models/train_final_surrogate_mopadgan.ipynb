{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airfoil_model_torch.py\n",
    "# PyTorch port of your TF2-compat (custom-BN) architecture.\n",
    "# - Residual blocks: BN -> LeakyReLU -> Conv, with (2,1) downsample when requested\n",
    "# - Depth schedule: 16 -> 32 -> 64 -> 128, with [2,2,2,2] blocks\n",
    "# - Global average pool, Dense(128) + BN + LeakyReLU, Dense(2) + Sigmoid\n",
    "# - Input expected as (N, n_points, 2)  -> we reshape to (N, 1, n_points, 2)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _same_padding_supported():\n",
    "    # PyTorch >= 1.10 supports padding='same' for Conv2d; we'll rely on it.\n",
    "    return True\n",
    "\n",
    "class BottleResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size=(4,2), downsample=False, bn_momentum=0.1):\n",
    "        super().__init__()\n",
    "        stride = (2,1) if downsample else (1,1)\n",
    "\n",
    "        # BN -> LReLU -> Conv\n",
    "        self.bn1 = nn.BatchNorm2d(in_ch, momentum=bn_momentum)\n",
    "        self.act1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride,\n",
    "                               padding='same' if _same_padding_supported() else 0, bias=False)\n",
    "\n",
    "        # BN -> LReLU -> Conv\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch, momentum=bn_momentum)\n",
    "        self.act2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=kernel_size, stride=(1,1),\n",
    "                               padding='same' if _same_padding_supported() else 0, bias=False)\n",
    "\n",
    "        # Skip path: 1x1 if stride or channel change\n",
    "        self.proj = None\n",
    "        if downsample or in_ch != out_ch:\n",
    "            self.proj = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.bn1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.act2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.proj is not None:\n",
    "            identity = self.proj(identity)\n",
    "\n",
    "        return out + identity\n",
    "\n",
    "class AirfoilSurrogate(nn.Module):\n",
    "    def __init__(self, n_points=64, depth=16, bn_momentum=0.1):\n",
    "        \"\"\"\n",
    "        n_points: number of points along the airfoil curve (height dimension).\n",
    "        Input shape during forward: (N, 1, n_points, 2)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        k = (4, 2)\n",
    "\n",
    "        # Stem: in_ch=1 -> depth\n",
    "        self.stem = nn.Conv2d(1, depth, kernel_size=k, stride=1,\n",
    "                              padding='same' if _same_padding_supported() else 0, bias=False)\n",
    "\n",
    "        # Residual groups [2,2,2,2] with downsample at group entry (except group0)\n",
    "        self.group0 = nn.Sequential(\n",
    "            BottleResBlock(depth, depth, kernel_size=k, downsample=False, bn_momentum=bn_momentum),\n",
    "            BottleResBlock(depth, depth, kernel_size=k, downsample=False, bn_momentum=bn_momentum),\n",
    "        )\n",
    "        self.group1 = nn.Sequential(\n",
    "            BottleResBlock(depth, depth*2, kernel_size=k, downsample=True,  bn_momentum=bn_momentum),\n",
    "            BottleResBlock(depth*2, depth*2, kernel_size=k, downsample=False, bn_momentum=bn_momentum),\n",
    "        )\n",
    "        self.group2 = nn.Sequential(\n",
    "            BottleResBlock(depth*2, depth*4, kernel_size=k, downsample=True,  bn_momentum=bn_momentum),\n",
    "            BottleResBlock(depth*4, depth*4, kernel_size=k, downsample=False, bn_momentum=bn_momentum),\n",
    "        )\n",
    "        self.group3 = nn.Sequential(\n",
    "            BottleResBlock(depth*4, depth*8, kernel_size=k, downsample=True,  bn_momentum=bn_momentum),\n",
    "            BottleResBlock(depth*8, depth*8, kernel_size=k, downsample=False, bn_momentum=bn_momentum),\n",
    "        )\n",
    "\n",
    "        # Tail BN + LeakyReLU\n",
    "        self.tail_bn  = nn.BatchNorm2d(depth*8, momentum=bn_momentum)\n",
    "        self.tail_act = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        # Global average pool to (1,1)\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        # Dense head: 128 -> BN -> LeakyReLU -> 2 -> Sigmoid\n",
    "        self.fc1 = nn.Linear(depth*8, 128, bias=False)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128, momentum=bn_momentum)\n",
    "        self.fc1_act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # He init (fan-in), matching VarianceScaling(scale=2.0, mode='fan_in')\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, a=0.2, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, a=0.2, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (N, 1, n_points, 2)  # channel-first\n",
    "        returns: (N, 2) in [0,1] via sigmoid\n",
    "        \"\"\"\n",
    "        x = self.stem(x)       # -> (N, depth, H, W)\n",
    "        x = self.group0(x)\n",
    "        x = self.group1(x)\n",
    "        x = self.group2(x)\n",
    "        x = self.group3(x)\n",
    "\n",
    "        x = self.tail_bn(x)\n",
    "        x = self.tail_act(x)\n",
    "\n",
    "        x = self.gap(x)        # (N, C, 1, 1)\n",
    "        x = torch.flatten(x, 1)  # (N, C)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_bn(x)\n",
    "        x = self.fc1_act(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 16:25:25.598640: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-18 16:25:25.632230: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-18 16:25:25.877682: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-18 16:25:26.899487: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'airfoil_model_torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDataset, DataLoader, random_split\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mairfoil_model_torch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AirfoilSurrogate\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ===================== HYPERPARAMETERS =====================\u001b[39;00m\n\u001b[1;32m     14\u001b[0m HYPERPARAMS \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Paths (Kaggle-style)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/data-mpi/xs_train_MPI.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpin_memory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m }\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'airfoil_model_torch'"
     ]
    }
   ],
   "source": [
    "# train_airfoil_surrogate_torch.py\n",
    "# Training script that mirrors your TF setup, using num_workers=2 and GPU.\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from airfoil_model_torch import AirfoilSurrogate\n",
    "\n",
    "# ===================== HYPERPARAMETERS =====================\n",
    "HYPERPARAMS = {\n",
    "    # Paths (Kaggle-style)\n",
    "    \"x_path\": r\"/kaggle/input/data-mpi/xs_train_MPI.npy\",\n",
    "    \"y_path\": r\"/kaggle/input/data-mpi-y/ys_train_MPI.npy\",\n",
    "    \"test_x_path\": r\"/kaggle/input/test-mpi/xs_test_MPI.npy\",\n",
    "    \"test_y_path\": r\"/kaggle/input/test-mpi-y/ys_test_MPI.npy\",\n",
    "\n",
    "    # Geometry\n",
    "    \"n_points\": 192,      # must match X.shape[1]\n",
    "\n",
    "    # Train/val\n",
    "    \"use_separate_test\": True,\n",
    "    \"val_split\": 0.2,\n",
    "    \"seed\": 42,\n",
    "\n",
    "    # Optimization\n",
    "    \"steps\": 10000,\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-4,\n",
    "    \"beta1\": 0.5,         # Adam beta1 ~ TF\n",
    "    \"weight_decay\": 1e-4, # L2 on weights (excludes BN & biases below)\n",
    "    \"save_interval\": 0,\n",
    "\n",
    "    # Output\n",
    "    \"outdir\": \"./runs/airfoil_run_torch\",\n",
    "\n",
    "    # DataLoader\n",
    "    \"num_workers\": 2,     # as requested\n",
    "    \"pin_memory\": True,\n",
    "}\n",
    "# ===========================================================\n",
    "\n",
    "def load_array(path):\n",
    "    if path.endswith(\".npy\"):\n",
    "        return np.load(path, mmap_mode=\"r\")\n",
    "    if path.endswith(\".npz\"):\n",
    "        data = np.load(path)\n",
    "        for key in (\"X\", \"Y\", \"arr_0\"):\n",
    "            if key in data:\n",
    "                return data[key]\n",
    "        raise ValueError(f\"No suitable key in {path}: expected 'X'/'Y'\")\n",
    "    raise ValueError(f\"Unsupported format for {path}. Use .npy or .npz\")\n",
    "\n",
    "def ensure_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def preprocess_numpy_to_torch(X):\n",
    "    \"\"\"\n",
    "    Input X: (N, n_points, 2) float32/float64\n",
    "    Returns torch.FloatTensor shaped (N, 1, n_points, 2) [NCHW]\n",
    "    \"\"\"\n",
    "    if X.ndim != 3 or X.shape[2] != 2:\n",
    "        raise ValueError(f\"X must be (N, n_points, 2); got {X.shape}\")\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    X = np.expand_dims(X, axis=1)  # (N, 1, n_points, 2)\n",
    "    return torch.from_numpy(X)\n",
    "\n",
    "def main(hp):\n",
    "    torch.manual_seed(hp[\"seed\"])\n",
    "    np.random.seed(hp[\"seed\"])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        # Optional: select GPU via environment CUDA_VISIBLE_DEVICES externally\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    ensure_dir(hp[\"outdir\"])\n",
    "    writer = SummaryWriter(log_dir=os.path.join(hp[\"outdir\"], \"logs\"))\n",
    "\n",
    "    # ---------- Load data ----------\n",
    "    X = load_array(hp[\"x_path\"])\n",
    "    Y = load_array(hp[\"y_path\"])\n",
    "    if X.shape[1] != hp[\"n_points\"]:\n",
    "        raise ValueError(f\"n_points ({hp['n_points']}) must match X.shape[1] ({X.shape[1]})\")\n",
    "\n",
    "    if hp[\"use_separate_test\"]:\n",
    "        X_train_np, Y_train_np = X, Y\n",
    "        X_test_np  = load_array(hp[\"test_x_path\"])\n",
    "        Y_test_np  = load_array(hp[\"test_y_path\"])\n",
    "        if X_test_np.shape[1:] != X.shape[1:]:\n",
    "            raise ValueError(f\"Test X shape {X_test_np.shape} incompatible with train X {X.shape}\")\n",
    "    else:\n",
    "        # simple split\n",
    "        N = X.shape[0]\n",
    "        idx = np.arange(N)\n",
    "        rng = np.random.RandomState(hp[\"seed\"])\n",
    "        rng.shuffle(idx)\n",
    "        split = int(N * (1.0 - hp[\"val_split\"]))\n",
    "        train_idx, test_idx = idx[:split], idx[split:]\n",
    "        X_train_np, Y_train_np = X[train_idx], Y[train_idx]\n",
    "        X_test_np,  Y_test_np  = X[test_idx],  Y[test_idx]\n",
    "\n",
    "    # ---------- Numpy -> Torch ----------\n",
    "    X_train = preprocess_numpy_to_torch(np.asarray(X_train_np))\n",
    "    X_test  = preprocess_numpy_to_torch(np.asarray(X_test_np))\n",
    "    Y_train = torch.from_numpy(np.asarray(Y_train_np, dtype=np.float32))\n",
    "    Y_test  = torch.from_numpy(np.asarray(Y_test_np,  dtype=np.float32))\n",
    "\n",
    "    train_ds = TensorDataset(X_train, Y_train)\n",
    "    test_ds  = TensorDataset(X_test,  Y_test)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=hp[\"batch_size\"], shuffle=True,\n",
    "        num_workers=hp[\"num_workers\"], pin_memory=hp[\"pin_memory\"], drop_last=False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=hp[\"batch_size\"], shuffle=False,\n",
    "        num_workers=hp[\"num_workers\"], pin_memory=hp[\"pin_memory\"], drop_last=False\n",
    "    )\n",
    "\n",
    "    # ---------- Model ----------\n",
    "    model = AirfoilSurrogate(n_points=hp[\"n_points\"], depth=16, bn_momentum=0.1).to(device)\n",
    "\n",
    "    # L1 loss to mirror TF reduce_mean(|y_true - y_pred|)\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    # Weight decay (L2) on conv/linear weights only (not BN, not biases)\n",
    "    decay, no_decay = [], []\n",
    "    for name, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        if any(nd in name for nd in [\"bn\", \"bias\"]):\n",
    "            no_decay.append(p)\n",
    "        else:\n",
    "            decay.append(p)\n",
    "    optim = torch.optim.Adam(\n",
    "        [{\"params\": decay, \"weight_decay\": hp[\"weight_decay\"]},\n",
    "         {\"params\": no_decay, \"weight_decay\": 0.0}],\n",
    "        lr=hp[\"lr\"], betas=(hp[\"beta1\"], 0.999)\n",
    "    )\n",
    "\n",
    "    # ---------- Training loop (by steps, like TF) ----------\n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    print(\"Starting training...\")\n",
    "    while global_step < hp[\"steps\"]:\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            pred = model(xb)             # (B, 2) in [0,1]\n",
    "            loss = criterion(pred, yb)\n",
    "\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            # quick eval on test set occasionally (cheap L1)\n",
    "            if global_step % 100 == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    test_losses = []\n",
    "                    for xbt, ybt in test_loader:\n",
    "                        xbt = xbt.to(device, non_blocking=True)\n",
    "                        ybt = ybt.to(device, non_blocking=True)\n",
    "                        predt = model(xbt)\n",
    "                        test_losses.append(criterion(predt, ybt).item())\n",
    "                    test_loss = float(np.mean(test_losses)) if test_losses else float(\"nan\")\n",
    "                model.train()\n",
    "\n",
    "                print(f\"{global_step}: train {loss.item():.6f}  test {test_loss:.6f}\")\n",
    "                writer.add_scalar(\"loss/train\", loss.item(), global_step)\n",
    "                writer.add_scalar(\"loss/test\",  test_loss,  global_step)\n",
    "\n",
    "            global_step += 1\n",
    "            if global_step >= hp[\"steps\"]:\n",
    "                break\n",
    "\n",
    "    # ---------- Save checkpoint ----------\n",
    "    ckpt_path = os.path.join(hp[\"outdir\"], \"model.pt\")\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"n_points\": hp[\"n_points\"],\n",
    "        \"depth\": 16,\n",
    "    }, ckpt_path)\n",
    "    print(f\"Model saved to: {ckpt_path}\")\n",
    "    writer.close()\n",
    "\n",
    "    # Sanity prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        xsm = X_test[:min(8, len(X_test))].to(device)\n",
    "        pred = model(xsm).cpu().numpy()\n",
    "        print(\"Sample predictions (first 5):\")\n",
    "        print(pred[:5])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(HYPERPARAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
